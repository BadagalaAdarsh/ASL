{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras import utils, callbacks\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "#from keras.preprocessing.image import load_img, img_to_array\n",
    "from skimage.transform import resize\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_directory = \"/home/adarsh/Jupyter_Notebook/American Sign Lang/ASL Data/asl_alphabet_train/asl_alphabet_train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = 29\n",
    "batch = 256\n",
    "epochs = 50\n",
    "lnr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 78300 images belonging to 29 classes.\n",
      "Found 8700 images belonging to 29 classes.\n"
     ]
    }
   ],
   "source": [
    "gen = ImageDataGenerator(rescale=1./255, validation_split=0.1) \n",
    "train = gen.flow_from_directory(\"/home/adarsh/Jupyter_Notebook/American Sign Lang/ASL Data/asl_alphabet_train/asl_alphabet_train\", \n",
    "                                                            target_size=(64, 64), subset=\"training\")\n",
    "val = gen.flow_from_directory(\"/home/adarsh/Jupyter_Notebook/American Sign Lang/ASL Data/asl_alphabet_train/asl_alphabet_train\", \n",
    "                                                            target_size=(64, 64), subset=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(learning_rate=lnr)\n",
    "model = Sequential()\n",
    "model.add(VGG16(weights='imagenet', include_top=False, input_shape=(64, 64, 3)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(29, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " 783/2447 [========>.....................] - ETA: 1:31:20 - loss: 0.3209 - accuracy: 0.9036"
     ]
    }
   ],
   "source": [
    "earlystopping = callbacks.EarlyStopping(monitor=\"val_loss\", mode=\"min\", \n",
    "                                        patience=5, restore_best_weights = True)\n",
    "\n",
    "history = model.fit(train, validation_data = val, epochs=epochs, shuffle=True, verbose=1, \n",
    "                    callbacks = [earlystopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 images belonging to 3 classes.\n",
      "[[7.8346152e-15 3.9848319e-24 1.0000000e+00]\n",
      " [1.0000000e+00 2.8225668e-16 5.7566397e-13]\n",
      " [4.9033878e-25 1.0000000e+00 1.5106818e-12]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 0, 1])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = ImageDataGenerator(rescale=1./255).flow_from_directory(\"/home/adarsh/Jupyter_Notebook/ASL/test_ind/\", \n",
    "                                                            target_size=(64, 64), class_mode=None)\n",
    "pred = model.predict(test)\n",
    "print(pred)\n",
    "pred = np.argmax(pred, axis=1)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('vgg16asl.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
